# -*- coding: utf-8 -*-
"""UNET_chatGPT_V3.3.2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1krymnzYHr8CGWPj17a1LwnBE6FbA7sVh

"""

import os
os.environ["XLA_FLAGS"] = "--xla_gpu_cuda_data_dir=/home/trung/cuda-12.3/nvvm/libdevice"


import numpy as np
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.utils import to_categorical
from sklearn.utils import shuffle

from tqdm import tqdm

from tensorflow.keras import callbacks
from sklearn.metrics import f1_score

import pandas as pd
from sklearn.metrics import confusion_matrix

import tifffile as tiff
import csv

import rasterio
import math

import keras 
import matplotlib.pyplot as plt

# Set GPU memory growth to avoid RAM overload
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)



def get_npy_filepaths(img_dir, mask_dir):
    img_files = sorted([os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith('.npy')])
    mask_files = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.npy')])
    return shuffle(img_files, mask_files, random_state=42)

def parse_image_mask(img_path, mask_path):
    def _load_npy(img, mask):
        img = img.decode("utf-8")
        mask = mask.decode("utf-8")

        img_arr = np.load(img).astype('float32')
        mask_arr = np.load(mask).astype('int32')
       

        # Handle mask shape
        if mask_arr.ndim == 3:
            mask_arr = mask_arr[:, :, 0]  # squeeze out extra dim if needed


        valid_mask = (mask_arr >= 0) & (mask_arr < NUM_CLASSES)

        clipped_mask = np.where(valid_mask, mask_arr, 0)  # temporarily set 255 to 0
        mask_arr = to_categorical(clipped_mask, num_classes=NUM_CLASSES).astype('float32')


        # Zero out invalid pixels (255) in the one-hot encoded mask
        mask_arr *= np.expand_dims(valid_mask, axis=-1)

        return img_arr, mask_arr

    img, mask = tf.numpy_function(_load_npy, [img_path, mask_path], [tf.float32, tf.float32])
    img.set_shape((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    mask.set_shape((IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES))

    return img, mask

def create_dataset(img_paths, mask_paths, batch_size=16, shuffle=True):
    dataset = tf.data.Dataset.from_tensor_slices((img_paths, mask_paths))
    dataset = dataset.map(parse_image_mask, num_parallel_calls=tf.data.AUTOTUNE)
    if shuffle:
        dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)
    return dataset



import logging

# Set up logging for debugging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_dataset_imbalance(img_paths, mask_paths, batch_size=16, minority_classes=None, repeat_factor=3, shuffle=True, shuffle_buffer_size=100, cache=False, seed=42):
    """
    Creates a TensorFlow dataset from image and mask file paths with oversampling for specified minority classes.

    Args:
        img_paths (list): List of paths to image .npy files.
        mask_paths (list): List of paths to mask .npy files.
        batch_size (int): Batch size for the dataset. Default is 16.
        minority_classes (list, optional): List of class indices to oversample. Default is None (no oversampling).
        repeat_factor (int): Number of times to repeat minority patches. Default is 3.
        shuffle (bool): Whether to shuffle the dataset. Default is True.
        shuffle_buffer_size (int): Size of the shuffle buffer. Default is 100.
        cache (bool): Whether to cache the dataset in memory. Default is False.
        seed (int): Random seed for shuffling and reproducibility. Default is 42.

    Returns:
        tf.data.Dataset: A batched and prefetched dataset with images and masks.
    """
    # Create dataset from file paths
    dataset = tf.data.Dataset.from_tensor_slices((img_paths, mask_paths))
    
    # Shuffle early to reduce memory pressure during oversampling
    if shuffle:
        dataset = dataset.shuffle(buffer_size=shuffle_buffer_size, seed=seed)
    
    # Map parsing function to load and preprocess images/masks
    def safe_parse_image_mask(img_path, mask_path):
        try:
            img, mask = parse_image_mask(img_path, mask_path)
            return img, mask
        except Exception as e:
            logger.error(f"Error parsing {img_path}: {e}")
            # Return dummy data to avoid crashing (adjust shapes as needed)
            return tf.zeros((128, 128, 25), dtype=tf.float32), tf.zeros((128, 128, 17), dtype=tf.float32)
    
    dataset = dataset.map(safe_parse_image_mask, num_parallel_calls=tf.data.AUTOTUNE)
    
    # Oversample patches containing minority classes if provided
    if minority_classes is not None:
        minority_classes = tf.constant(minority_classes, dtype=tf.int64)
        def filter_minority(img, mask):
            # Get class indices for the mask (shape: [H, W])
            class_indices = tf.argmax(mask, axis=-1)
            # Check if any pixel's class is in minority_classes
            is_minority = tf.reduce_any(tf.reduce_any(tf.equal(class_indices[:, :, None], minority_classes), axis=[0, 1]))
            return is_minority
        
        minority_dataset = dataset.filter(filter_minority)
        minority_dataset = minority_dataset.repeat(repeat_factor)  # Oversample with configurable repeat
        dataset = dataset.concatenate(minority_dataset)
    
    # Cache if enabled (use cautiously due to memory)
    if cache:
        dataset = dataset.cache()
    
    # Batch and prefetch for performance
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)
    
    return dataset






def unetpp_model_tf(input_shape, num_classes, l2_factor=1e-4):
    inputs = tf.keras.layers.Input(shape=input_shape)

    def conv_block(x, filters, dropout_rate=0.3):
        x = tf.keras.layers.Conv2D(filters, 3, padding='same',
                                   kernel_regularizer=tf.keras.regularizers.l2(l2_factor))(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('relu')(x)
        x = tf.keras.layers.Conv2D(filters, 3, padding='same',
                                   kernel_regularizer=tf.keras.regularizers.l2(l2_factor))(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('relu')(x)
        x = tf.keras.layers.Dropout(dropout_rate)(x)
        return x

    def upsample_concat(x, skip):
        x = tf.keras.layers.Conv2DTranspose(tf.keras.backend.int_shape(skip)[-1], 2, strides=2, padding='same')(x)
        return tf.keras.layers.concatenate([x, skip])

    # Encoder path (8 levels)
    x00 = conv_block(inputs, 16, 0.1)
    p0 = tf.keras.layers.MaxPooling2D()(x00)

    x10 = conv_block(p0, 32, 0.12)
    p1 = tf.keras.layers.MaxPooling2D()(x10)

    x20 = conv_block(p1, 64, 0.15)
    p2 = tf.keras.layers.MaxPooling2D()(x20)

    x30 = conv_block(p2, 128, 0.18)
    p3 = tf.keras.layers.MaxPooling2D()(x30)

    x40 = conv_block(p3, 256, 0.20)
    p4 = tf.keras.layers.MaxPooling2D()(x40)

    x50 = conv_block(p4, 512, 0.25)
    p5 = tf.keras.layers.MaxPooling2D()(x50)

    x60 = conv_block(p5, 1024, 0.30)
    p6 = tf.keras.layers.MaxPooling2D()(x60)

    x70 = conv_block(p6, 2048, 0.35)  # bottleneck

    # Decoder with nested connections (partial, expand as needed)
    x61 = conv_block(upsample_concat(x70, x60), 1024, 0.3)
    x51 = conv_block(upsample_concat(x61, x50), 512, 0.25)
    x41 = conv_block(upsample_concat(x51, x40), 256, 0.20)
    x31 = conv_block(upsample_concat(x41, x30), 128, 0.18)
    x21 = conv_block(upsample_concat(x31, x20), 64, 0.15)
    x11 = conv_block(upsample_concat(x21, x10), 32, 0.12)
    x01 = conv_block(upsample_concat(x11, x00), 16, 0.1)

    outputs = tf.keras.layers.Conv2D(num_classes, 1, activation='softmax')(x01)

    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

def unetpp_model_tf_7layers(input_shape, num_classes, l2_factor=1e-4):
    inputs = tf.keras.layers.Input(shape=input_shape)

    def conv_block(x, filters, dropout_rate=0.3):
        x = tf.keras.layers.Conv2D(filters, 3, padding='same',
                                   kernel_regularizer=tf.keras.regularizers.l2(l2_factor))(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('relu')(x)
        x = tf.keras.layers.Conv2D(filters, 3, padding='same',
                                   kernel_regularizer=tf.keras.regularizers.l2(l2_factor))(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('relu')(x)
        x = tf.keras.layers.Dropout(dropout_rate)(x)
        return x

    def upsample_concat(x, skip):
        x = tf.keras.layers.Conv2DTranspose(tf.keras.backend.int_shape(skip)[-1], 2, strides=2, padding='same')(x)
        return tf.keras.layers.concatenate([x, skip])

    # Encoder path (7 levels instead of 8)
    x00 = conv_block(inputs, 16, 0.1)
    p0 = tf.keras.layers.MaxPooling2D()(x00)

    x10 = conv_block(p0, 32, 0.12)
    p1 = tf.keras.layers.MaxPooling2D()(x10)

    x20 = conv_block(p1, 64, 0.15)
    p2 = tf.keras.layers.MaxPooling2D()(x20)

    x30 = conv_block(p2, 128, 0.18)
    p3 = tf.keras.layers.MaxPooling2D()(x30)

    x40 = conv_block(p3, 256, 0.20)
    p4 = tf.keras.layers.MaxPooling2D()(x40)

    x50 = conv_block(p4, 512, 0.25)
    p5 = tf.keras.layers.MaxPooling2D()(x50)

    x60 = conv_block(p5, 1024, 0.30)  # bottleneck (last level now)

    # Decoder with nested connections (starts from x60 instead of x70)
    x51 = conv_block(upsample_concat(x60, x50), 512, 0.25)
    x41 = conv_block(upsample_concat(x51, x40), 256, 0.20)
    x31 = conv_block(upsample_concat(x41, x30), 128, 0.18)
    x21 = conv_block(upsample_concat(x31, x20), 64, 0.15)
    x11 = conv_block(upsample_concat(x21, x10), 32, 0.12)
    x01 = conv_block(upsample_concat(x11, x00), 16, 0.1)

    outputs = tf.keras.layers.Conv2D(num_classes, 1, activation='softmax')(x01)

    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

def unet96x96(input_shape, num_classes, l2_factor=1e-4):
    """
    U-Net++ model adjusted for a 96x96 input, compatible with Keras 3.0.
    """
    inputs = keras.layers.Input(shape=input_shape)

    def conv_block(x, filters, dropout_rate=0.3):
        x = keras.layers.Conv2D(filters, 3, padding='same',
                                   kernel_regularizer=tf.keras.regularizers.l2(l2_factor))(x)
        x = keras.layers.BatchNormalization()(x)
        x = keras.layers.Activation('relu')(x)
        x = keras.layers.Conv2D(filters, 3, padding='same',
                                   kernel_regularizer=tf.keras.regularizers.l2(l2_factor))(x)
        x = keras.layers.BatchNormalization()(x)
        x = keras.layers.Activation('relu')(x)
        x = keras.layers.Dropout(dropout_rate)(x)
        return x

    def upsample_concat(x, skip):
        # CORRECTED: Use .shape instead of keras.backend.int_shape() for Keras 3.0
        skip_shape = skip.shape

        # Up-sample the input tensor
        x = keras.layers.Conv2DTranspose(skip_shape[-1], 2, strides=2, padding='same')(x)

        # Resize the upsampled tensor to match the skip connection's spatial shape
        x = keras.layers.Resizing(height=skip_shape[1], width=skip_shape[2])(x)

        # Concatenate the resized tensor with the skip connection
        return keras.layers.concatenate([x, skip])

    # Encoder path (6 levels instead of 7)
    x00 = conv_block(inputs, 16, 0.1)
    p0 = keras.layers.MaxPooling2D()(x00) # 96 -> 48

    x10 = conv_block(p0, 32, 0.12)
    p1 = keras.layers.MaxPooling2D()(x10) # 48 -> 24

    x20 = conv_block(p1, 64, 0.15)
    p2 = keras.layers.MaxPooling2D()(x20) # 24 -> 12

    x30 = conv_block(p2, 128, 0.18)
    p3 = keras.layers.MaxPooling2D()(x30) # 12 -> 6

    x40 = conv_block(p3, 256, 0.20)
    p4 = keras.layers.MaxPooling2D()(x40) # 6 -> 3

    x50 = conv_block(p4, 512, 0.25)
    p5 = keras.layers.MaxPooling2D()(x50) # 3 -> 1

    # The new bottleneck is at this level
    x60 = conv_block(p5, 1024, 0.30)

    # Decoder with nested connections (adjusted for 6 levels)
    x51 = conv_block(upsample_concat(x60, x50), 512, 0.25)
    x41 = conv_block(upsample_concat(x51, x40), 256, 0.20)
    x31 = conv_block(upsample_concat(x41, x30), 128, 0.18)
    x21 = conv_block(upsample_concat(x31, x20), 64, 0.15)
    x11 = conv_block(upsample_concat(x21, x10), 32, 0.12)
    x01 = conv_block(upsample_concat(x11, x00), 16, 0.1)

    outputs = keras.layers.Conv2D(num_classes, 1, activation='softmax')(x01)

    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

def classify_full_image(image_path, model, patch_size, stride=32):
    img = tiff.imread(image_path)  # shape: (H, W, Bands)i
    
    # Add these 2 lines for alpha earth image differnt in shape ordered
    
    if img.ndim == 3 and img.shape[0] < img.shape[1] and img.shape[0] < img.shape[2]:
        img = np.transpose(img, (1, 2, 0))  # â†’ (H, W, Bands)
    #------END UDPATED      
        
    H, W, C = img.shape
    prob_map = np.zeros((H, W, model.output_shape[-1]), dtype=np.float32)
    count_map = np.zeros((H, W, 1), dtype=np.float32)

    # Calculate total number of steps for progress bar
    total_steps = ((H - 1) // stride + 1) * ((W - 1) // stride + 1)
    pbar = tqdm(total=total_steps, desc="Predicting patches")


    for i in range(0,H, stride):
        for j in range(0, W , stride):
            i_start = min(i, H - patch_size)
            j_start = min(j, W - patch_size)
            
            patch = img[i_start:i_start+patch_size, j_start:j_start+patch_size, :]
            patch = patch.astype('float32')
            patch = np.nan_to_num(patch, nan=0.0, posinf=0.0, neginf=0.0)
            
            
            pred = model.predict(patch[np.newaxis, ...],verbose=0)[0]  # shape: (patch_size, patch_size, num_classes)

            prob_map[i_start:i_start+patch_size, j_start:j_start+patch_size, :] += pred
            count_map[i_start:i_start+patch_size, j_start:j_start+patch_size, :] += 1
            pbar.update(1)
    pbar.close()
    # Avoid division by zero
    count_map[count_map == 0] = 1
    prob_map /= count_map
    prediction_map = np.argmax(prob_map, axis=-1).astype(np.uint8)
    return prediction_map

def save_classified_geotiff(classified_array, reference_path, output_path):
    # Use a reference Sentinel-1 image for geo info
    with rasterio.open(reference_path) as src:
        profile = src.profile
        profile.update({
            'count': 1,
            'dtype': 'uint8',  # change based on your class dtype
            'compress': 'lzw',
            'nodata': 255
        })
        # Replace invalid values (-inf, inf, NaN) with nodata value
    classified_array = np.nan_to_num(classified_array, nan=255, posinf=255, neginf=255)
    classified_array = classified_array.astype(np.uint8)

    with rasterio.open(output_path, 'w', **profile) as dst:
        dst.write(classified_array.astype('byte'), 1)

def track_class_counts(dataset, num_classes):
    """
    Tracks class counts for a one-hot encoded dataset by summing along axes.
    """
    class_counts = np.zeros(num_classes, dtype=np.int64)

    for x_batch, y_batch in dataset:
        y_np = y_batch.numpy()
        
        # Sum along the batch, height, and width axes to count '1's per channel
        batch_counts = np.sum(y_np, axis=(0, 1, 2))
        
        class_counts += batch_counts.astype(np.int64)
        
    return class_counts

class DynamicWeightsCallback(tf.keras.callbacks.Callback):
    def __init__(self, class_counts, smoothing=1e-6):
        super().__init__()
        self.class_counts = class_counts
        self.smoothing = smoothing
        self.weights = self._compute_weights()

    def _compute_weights(self):
        # Slice the counts array to remove the count for Class 0
        counts_without_class_0 = self.class_counts[1:]
    
        # Calculate weights only for classes 1 and above
        total_pixels = np.sum(counts_without_class_0)
    
        # Use a small smoothing value to avoid division by zero for other classes
        smoothing = 1e-6
        frequencies = counts_without_class_0 / (total_pixels + smoothing)
        weights = 1.0 / (frequencies + smoothing)
    
        # Normalize the weights so they sum to 1
        normalized_weights = weights / np.sum(weights)
    
        # Create the final weights array with a weight of 0 for Class 0
        final_weights = np.insert(normalized_weights, 0, 0.0)
    
        return final_weights.astype(np.float32)

    def get_weights(self):
        return self.weights.astype(np.float32)

    def on_epoch_end(self, epoch, logs=None):
        self.weights = self._compute_weights()

#---PRINT CLASS IOU
class PerClassIoU(tf.keras.metrics.Metric):
    def __init__(self, num_classes, ignore_classes=[255], name="per_class_iou", **kwargs):
        super().__init__(name=name, **kwargs)
        self.num_classes = num_classes
        self.ignore_classes = tf.constant(ignore_classes, dtype=tf.int64)
        self.valid_classes = tf.constant(
            [i for i in range(num_classes) if i not in ignore_classes], dtype=tf.int64
        )
        self.intersections = self.add_weight(
            name="intersections", shape=(num_classes,), initializer="zeros"
        )
        self.unions = self.add_weight(
            name="unions", shape=(num_classes,), initializer="zeros"
        )

    def update_state(self, y_true, y_pred, sample_weight=None):
        # Convert from one-hot to class indices
        y_true = tf.argmax(y_true, axis=-1)
        y_pred = tf.argmax(y_pred, axis=-1)

        # Flatten
        y_true = tf.reshape(y_true, [-1])
        y_pred = tf.reshape(y_pred, [-1])

        # Filter out ignored classes (0 and 255)
        ignore_mask = tf.reduce_any(tf.equal(tf.expand_dims(y_true, -1), self.ignore_classes), axis=-1)
        valid_mask = tf.logical_not(ignore_mask)
        y_true = tf.boolean_mask(y_true, valid_mask)
        y_pred = tf.boolean_mask(y_pred, valid_mask)

        # Compute confusion matrix
        cm = tf.math.confusion_matrix(
            y_true, y_pred, num_classes=self.num_classes, dtype=tf.float32
        )

        # Diagonal: intersection
        intersection = tf.linalg.diag_part(cm)
        union = tf.reduce_sum(cm, axis=0) + tf.reduce_sum(cm, axis=1) - intersection
        
        self.intersections.assign_add(intersection)
        self.unions.assign_add(union)


    def result(self):
        # Return IoU for valid classes only
        iou = self.intersections / (self.unions + 1e-7)
        return tf.gather(iou, self.valid_classes)

    def reset_states(self):
        self.intersections.assign(tf.zeros_like(self.intersections))
        self.unions.assign(tf.zeros_like(self.unions))

#class PrintPerClassIoU(tf.keras.callbacks.Callback):
#    def __init__(self, metric, class_names=None):
#        super().__init__()
#        self.metric = metric
#        self.class_names = class_names or [f"Class {i}" for i in range(metric.num_classes)]

#    def on_epoch_end(self, epoch, logs=None):
#        ious = self.metric.intersections.numpy() / (self.metric.unions.numpy() + 1e-7)
#        valid_classes = self.metric.valid_classes.numpy()
    
#        print(f"\nðŸ” Per-Class IoU at Epoch {epoch + 1}:")
#        for i, class_id in enumerate(valid_classes):
#            class_name = self.class_names[class_id] if class_id < len(self.class_names) else f"Class {class_id}"
#            print(f"  {class_name:>10}: {ious[class_id]:.4f}")

#---PRINT CLASS IOU---------

from tensorflow.keras.saving import register_keras_serializable
@register_keras_serializable()
class CombinedLoss(tf.keras.losses.Loss):
    #def __init__(self, get_weights, ignore_class=255, alpha=1.0, beta=1.0, name="combined_loss", **kwargs):
    def __init__(self, get_weights, ignore_class=255, alpha=tf.Variable(1.0), beta=tf.Variable(1.0), gamma = 1.1, name="combined_loss", **kwargs):
        super().__init__(name=name, **kwargs)
        self.get_weights = get_weights
        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma
        self.ignore_class = ignore_class

    def call(self, y_true, y_pred):
        weights = tf.constant(self.get_weights(), dtype=tf.float32)
        
        # Convert one-hot to class indices to create mask
        y_true_cls = tf.argmax(y_true, axis=-1)
        #mask = tf.not_equal(y_true_cls, self.ignore_class)
        #Ignore class 0
        mask = tf.logical_and(
            tf.not_equal(y_true_cls, self.ignore_class),
            tf.not_equal(y_true_cls, 0)
            )
            

        # Apply mask
        mask = tf.cast(mask, tf.float32)

        # Compute weighted CE
        ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)  # shape: (batch, H, W)
        pixel_weights = tf.reduce_sum(y_true * weights, axis=-1)       # shape: (batch, H, W)
        weighted_ce = ce * pixel_weights * mask
        loss_ce = tf.math.divide_no_nan(tf.reduce_sum(weighted_ce), tf.reduce_sum(mask))

        # Compute masked Dice loss
        intersection = tf.reduce_sum(y_true * y_pred * tf.expand_dims(mask, -1))
        denominator = tf.reduce_sum((y_true + y_pred) * tf.expand_dims(mask, -1))
        dice = (2. * intersection + 1e-7) / (denominator + 1e-7)
        loss_dice = 1. - dice

        # ==================== UPDATED: Compute Focal Loss ====================
        # Clip y_pred to avoid log(0)
        y_pred_clipped = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1. - tf.keras.backend.epsilon())
    
        # Get the predicted probabilities for the true class (pt)
        pt = tf.reduce_sum(y_true * y_pred_clipped, axis=-1)
    
        # Calculate the cross-entropy part
        ce = -tf.math.log(pt)
    
        # Calculate the modulating factor (1 - pt)^gamma
        modulating_factor = tf.pow(1. - pt, self.gamma)
    
        # Combine to get the per-pixel focal loss
        focal_loss_per_pixel = ce * modulating_factor
    
        # Apply pixel weights and mask
        pixel_weights = tf.reduce_sum(y_true * weights, axis=-1)
        weighted_focal_loss = focal_loss_per_pixel * pixel_weights * mask
    
        # Calculate the final focal loss
        loss_focal = tf.math.divide_no_nan(tf.reduce_sum(weighted_focal_loss), tf.reduce_sum(mask))
        # =====================================================================

        #return self.alpha * loss_focal + self.beta * loss_dice
        return self.alpha * loss_ce + self.beta * loss_dice

    def get_config(self):
        config = super().get_config()
        config.update({
            #"alpha": self.alpha,
            #"beta": self.beta,
            "alpha": float(self.alpha.numpy()),
            "beta": float(self.beta.numpy()),    
            "ignore_class": self.ignore_class
        })
        return config

    @classmethod
    def from_config(cls, config, get_weights=None):
        if get_weights is None:
            raise ValueError("You must provide 'get_weights' when loading this loss, which cannot be deserialized automatically.")
        return cls(get_weights=get_weights, **config)

class AdaptiveLossCallback(tf.keras.callbacks.Callback):
    def __init__(
        self,
        loss,
        validation_data,
        num_classes,
        ignore_classes=[255],
        csv_path="adaptive_loss_log.csv",
        patience=3,
        slope_scale=1.5,
        min_weight=0.1,
        max_weight=0.9,
        cooldown=2,
    ):
        super().__init__()
        self.loss = loss
        self.validation_data = validation_data
        self.num_classes = num_classes
        self.ignore_classes = ignore_classes
        self.csv_path = csv_path
        self.patience = patience
        self.slope_scale = slope_scale
        self.min_weight = min_weight
        self.max_weight = max_weight
        self.cooldown = cooldown
        self.cooldown_counter = 0
        self.wait = 0
        self.best_iou = 0.0
        self.val_ious = []
        self.history = {
            "epoch": [],
            "val_loss": [],
            "val_mean_iou": [],
            "alpha": [],
            "beta": [],
        }

        self.per_class_iou_header = [f"iou_class_{i}" for i in range(self.num_classes)]

        # Prepare CSV header
        if not os.path.exists(csv_path):
            with open(csv_path, mode="w", newline="") as f:
                writer = csv.writer(f)
                writer.writerow(["epoch", "val_loss", "val_mean_iou", "alpha", "beta"] + self.per_class_iou_header)

    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        val_iou = logs.get("val_mean_io_u")
        val_loss = logs.get("val_loss")

        if val_iou is None:
            print("val_mean_io_u not found in logs.")
            return

        alpha = float(self.loss.alpha.numpy())
        beta = float(self.loss.beta.numpy())

        # Compute per-class IoU
        per_class_ious = self._compute_per_class_iou()

        # Save logs to internal history
        self.val_ious.append(val_iou)
        self.history["epoch"].append(epoch)
        self.history["val_loss"].append(val_loss)
        self.history["val_mean_iou"].append(val_iou)
        self.history["alpha"].append(alpha)
        self.history["beta"].append(beta)

        # Save to CSV
        with open(self.csv_path, mode="a", newline="") as f:
            writer = csv.writer(f)
            writer.writerow([epoch, val_loss, val_iou, alpha, beta] + per_class_ious)

        if len(self.val_ious) <= self.patience:
            return

        x = np.arange(-self.patience, 1)
        y = self.val_ious[-self.patience - 1:]
        slope = np.polyfit(x, y, 1)[0]

        if self.cooldown_counter > 0:
            self.cooldown_counter -= 1
            return

        if val_iou > self.best_iou:
            self.best_iou = val_iou
            self.wait = 0
            return
        else:
            self.wait += 1

        if self.wait >= self.patience:
            delta = slope * self.slope_scale
            current_alpha = alpha
            current_beta = beta

            alpha_a = np.clip(current_alpha * (1 + delta), self.min_weight, self.max_weight)
            beta_a = np.clip(current_beta * (1 - delta), self.min_weight, self.max_weight)

            alpha_b = np.clip(current_alpha * (1 - delta), self.min_weight, self.max_weight)
            beta_b = np.clip(current_beta * (1 + delta), self.min_weight, self.max_weight)

            print(f"\n[AdaptiveLoss] Epoch {epoch}: slope={slope:.4f}, trying both â†‘Î± and â†“Î±")

            self.loss.alpha.assign(alpha_a)
            self.loss.beta.assign(beta_a)
            iou_a = self._evaluate_on_validation().get("val_mean_io_u", 0)

            self.loss.alpha.assign(alpha_b)
            self.loss.beta.assign(beta_b)
            iou_b = self._evaluate_on_validation().get("val_mean_io_u", 0)

            if iou_a >= iou_b:
                self.loss.alpha.assign(alpha_a)
                self.loss.beta.assign(beta_a)
                print(f"[AdaptiveLoss] â†‘Î± chosen: Î±={alpha_a:.4f}, Î²={beta_a:.4f}, val_mIoU={iou_a:.4f}")
            else:
                self.loss.alpha.assign(alpha_b)
                self.loss.beta.assign(beta_b)
                print(f"[AdaptiveLoss] â†“Î± chosen: Î±={alpha_b:.4f}, Î²={beta_b:.4f}, val_mIoU={iou_b:.4f}")

            self.wait = 0
            self.cooldown_counter = self.cooldown

    def _evaluate_on_validation(self):
        logs = self.model.evaluate(self.validation_data, return_dict=True, verbose=0)
        return logs

    def _compute_per_class_iou(self):
        y_true_list = []
        y_pred_list = []

        for x_batch, y_true in self.validation_data:
            y_pred = self.model.predict(x_batch, verbose=0)
            y_true = tf.argmax(y_true, axis=-1)
            y_pred = tf.argmax(y_pred, axis=-1)

            y_true_list.append(tf.reshape(y_true, [-1]))
            y_pred_list.append(tf.reshape(y_pred, [-1]))

            y_true_flat = tf.concat(y_true_list, axis=0)
            y_pred_flat = tf.concat(y_pred_list, axis=0)

            per_class_ious = []

            for i in range(self.num_classes):
                if i in self.ignore_classes:
                    per_class_ious.append(None)
                    continue

            true_mask = tf.equal(y_true_flat, i)
            pred_mask = tf.equal(y_pred_flat, i)
            intersection = tf.reduce_sum(tf.cast(tf.logical_and(true_mask, pred_mask), tf.float32))
            union = tf.reduce_sum(tf.cast(tf.logical_or(true_mask, pred_mask), tf.float32))

            iou = (intersection / union).numpy() if union.numpy() > 0 else 0.0
            per_class_ious.append(round(iou, 4))

        return per_class_ious

    def on_train_end(self, logs=None):
        self._plot_metrics()

    def _plot_metrics(self):
        epochs = self.history["epoch"]

        plt.figure(figsize=(14, 10))

        plt.subplot(2, 2, 1)
        plt.plot(epochs, self.history["val_mean_iou"], marker="o", color="green")
        plt.title("Validation Mean IoU")
        plt.xlabel("Epoch")
        plt.ylabel("IoU")
        plt.grid(True)

        plt.subplot(2, 2, 2)
        plt.plot(epochs, self.history["val_loss"], marker="o", color="red")
        plt.title("Validation Loss")
        plt.xlabel("Epoch")
        plt.ylabel("Loss")
        plt.grid(True)

        plt.subplot(2, 2, 3)
        plt.plot(epochs, self.history["alpha"], marker="o", color="blue")
        plt.title("Alpha Over Epochs")
        plt.xlabel("Epoch")
        plt.ylabel("Alpha")
        plt.grid(True)

        plt.subplot(2, 2, 4)
        plt.plot(epochs, self.history["beta"], marker="o", color="orange")
        plt.title("Beta Over Epochs")
        plt.xlabel("Epoch")
        plt.ylabel("Beta")
        plt.grid(True)
        plt.tight_layout()
        plt.savefig("adaptive_loss_plot.png", dpi=300)
"""
class IoU_F1_Logger(callbacks.Callback):
    def __init__(self, train_ds, val_ds, num_classes, csv_path="training_log_valTrain.csv"):
        super().__init__()
        self.train_ds = train_ds
        self.val_ds = val_ds
        self.num_classes = num_classes
        self.csv_path = csv_path
        # Write header
        with open(self.csv_path, "w", newline="") as f:
            writer = csv.writer(f)
            header = ["epoch","set","loss"] + \
                     [f"iou_class_{i+1}" for i in range(num_classes)] + \
                     [f"f1_class_{i+1}" for i in range(num_classes)]
            writer.writerow(header)

    def on_epoch_end(self, epoch, logs=None):
        for name, dataset in [("train", self.train_ds), ("val", self.val_ds)]:
            all_preds = []
            all_labels = []
            losses = []
            for imgs, masks in dataset:
                preds = self.model.predict(imgs, verbose=0)
                loss = self.model.evaluate(imgs, masks, verbose=0)
                losses.append(loss)
                preds_idx = np.argmax(preds, axis=-1).flatten()
                labels_idx = np.argmax(masks.numpy(), axis=-1).flatten()
                # mask out ignored
                mask_ignore = labels_idx == -1
                preds_idx = preds_idx[~mask_ignore]
                labels_idx = labels_idx[~mask_ignore]
                all_preds.append(preds_idx)
                all_labels.append(labels_idx)
            all_preds = np.concatenate(all_preds)
            all_labels = np.concatenate(all_labels)
            ious, f1s = [], []
            for c in range(self.num_classes):
                true_c = all_labels==c
                pred_c = all_preds==c
                inter = np.sum(true_c & pred_c)
                union = np.sum(true_c | pred_c)
                iou = (inter + 1e-6)/(union + 1e-6)
                ious.append(iou)
                f1 = f1_score(true_c, pred_c)
                f1s.append(f1)
            # write row
            with open(self.csv_path, "a", newline="") as f:
                writer = csv.writer(f)
                writer.writerow([epoch+1, name, np.mean(losses)] + ious + f1s)
"""

"""
class IoU_F1_Logger(callbacks.Callback):
    def __init__(self, train_ds, val_ds, num_classes, csv_path="training_log_valTrain.csv"):
        super().__init__()
        self.train_ds = train_ds
        self.val_ds = val_ds
        self.num_classes = num_classes
        self.csv_path = csv_path
        
        # --- Write CSV header ---
        header = (
            ["epoch", "set", "loss", "accuracy", "precision", "recall", "mean_iou"] +
            [f"iou_class_{i+1}" for i in range(num_classes)] +
            [f"f1_class_{i+1}" for i in range(num_classes)]
        )
        with open(self.csv_path, "w", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(header)

    def on_epoch_end(self, epoch, logs=None):
        for name, dataset in [("train", self.train_ds), ("val", self.val_ds)]:
            all_preds, all_labels = [], []
            losses, accs, precs, recs, mean_ious = [], [], [], [], []

            for imgs, masks in dataset:
                # Predict
                preds = self.model.predict(imgs, verbose=0)
                results = self.model.evaluate(imgs, masks, verbose=0)

                # Handle list/tuple output from evaluate()
                if isinstance(results, (list, tuple)):
                    loss_value = results[0]
                    # Try to extract metrics if exist
                    acc_value = results[1] if len(results) > 1 else np.nan
                    mean_iou_value = results[2] if len(results) > 2 else np.nan
                    prec_value = results[3] if len(results) > 3 else np.nan
                    rec_value = results[4] if len(results) > 4 else np.nan
                else:
                    loss_value = results
                    acc_value = mean_iou_value = prec_value = rec_value = np.nan

                # Store metrics
                losses.append(loss_value)
                accs.append(acc_value)
                mean_ious.append(mean_iou_value)
                precs.append(prec_value)
                recs.append(rec_value)

                # Flatten predictions and labels
                preds_idx = np.argmax(preds, axis=-1).flatten()
                labels_idx = np.argmax(masks.numpy(), axis=-1).flatten()

                # Mask out ignored (-1) labels if exist
                mask_ignore = labels_idx == -1
                preds_idx = preds_idx[~mask_ignore]
                labels_idx = labels_idx[~mask_ignore]

                all_preds.append(preds_idx)
                all_labels.append(labels_idx)

            # Concatenate all predictions and labels
            all_preds = np.concatenate(all_preds)
            all_labels = np.concatenate(all_labels)

            # Compute per-class IoU and F1
            ious, f1s = [], []
            for c in range(self.num_classes):
                true_c = all_labels == c
                pred_c = all_preds == c
                inter = np.sum(true_c & pred_c)
                union = np.sum(true_c | pred_c)
                iou = (inter + 1e-6) / (union + 1e-6)
                ious.append(iou)

                f1 = f1_score(true_c, pred_c, zero_division=0)
                f1s.append(f1)

            # Aggregate metrics
            mean_loss = np.mean(losses)
            mean_acc = np.nanmean(accs)
            mean_prec = np.nanmean(precs)
            mean_rec = np.nanmean(recs)
            mean_iou_val = np.nanmean(mean_ious)

            # Write row to CSV
            with open(self.csv_path, "a", newline="") as f:
                writer = csv.writer(f)
                writer.writerow(
                    [epoch + 1, name, mean_loss, mean_acc, mean_prec, mean_rec, mean_iou_val] + ious + f1s
                )

            print(f"âœ… Epoch {epoch+1:03d} | {name.upper()} - Loss: {mean_loss:.4f}, "
                  f"Acc: {mean_acc:.4f}, Prec: {mean_prec:.4f}, Rec: {mean_rec:.4f}, mIoU: {mean_iou_val:.4f}")
"""
#Generated by GROK

class IoU_F1_Logger(callbacks.Callback):
    def __init__(self, train_ds, val_ds, num_classes, class_names=None, csv_path="metrics_log.csv", max_batches=10):
        super().__init__()
        self.train_ds = train_ds.cache().prefetch(tf.data.AUTOTUNE)
        self.val_ds = val_ds.cache().prefetch(tf.data.AUTOTUNE)
        self.num_classes = num_classes
        self.class_names = class_names if class_names else [f"Class_{i}" for i in range(num_classes)]
        self.csv_path = csv_path
        self.max_batches = max_batches

        # Write CSV header
        header = (
            ["epoch", "set", "loss", "accuracy", "mean_iou"] +
            [f"iou_{self.class_names[i]}" for i in range(num_classes)] +
            [f"precision_{self.class_names[i]}" for i in range(num_classes)] +
            [f"recall_{self.class_names[i]}" for i in range(num_classes)] +
            [f"f1_{self.class_names[i]}" for i in range(num_classes)] if self.csv_path == "val" else []
        )
        with open(self.csv_path, "w", newline="") as f:
            writer = csv.writer(f)
            writer.writerow(header)

    def on_epoch_end(self, epoch, logs=None):
        rows = []
        for name, dataset in [("train", self.train_ds), ("val", self.val_ds)]:
            all_preds, all_labels = [], []
            losses, accs, mean_ious = [], [], []

            # Process limited batches
            for imgs, masks in dataset.take(self.max_batches):
                # Evaluate with single forward pass
                results = self.model.evaluate(imgs, masks, verbose=0, return_dict=True)
                loss_value = results.get('loss', np.nan)
                acc_value = results.get('accuracy', np.nan)
                mean_iou_value = results.get('mean_iou', np.nan)

                # Get predictions for per-class metrics
                preds = self.model(imgs, training=False)
                preds_idx = tf.argmax(preds, axis=-1)
                labels_idx = tf.argmax(masks, axis=-1)
                mask_ignore = labels_idx != -1  # Handle ignored labels
                preds_idx = tf.boolean_mask(preds_idx, mask_ignore).numpy()
                labels_idx = tf.boolean_mask(labels_idx, mask_ignore).numpy()

                losses.append(loss_value)
                accs.append(acc_value)
                mean_ious.append(mean_iou_value)
                all_preds.append(preds_idx)
                all_labels.append(labels_idx)

            # Concatenate predictions and labels
            all_preds = np.concatenate(all_preds)
            all_labels = np.concatenate(all_labels)

            # Compute per-class IoU, precision, recall, and F1 (val only)
            cm = confusion_matrix(all_labels, all_preds, labels=range(self.num_classes))
            ious, precisions, recalls, f1s = [], [], [], []
            for c in range(self.num_classes):
                inter = cm[c, c]
                union = np.sum(cm[c, :]) + np.sum(cm[:, c]) - inter
                iou = (inter + 1e-6) / (union + 1e-6) if union > 0 else 0
                prec = inter / (np.sum(cm[:, c]) + 1e-6) if np.sum(cm[:, c]) > 0 else 0
                rec = inter / (np.sum(cm[c, :]) + 1e-6) if np.sum(cm[c, :]) > 0 else 0
                f1 = 2 * (prec * rec) / (prec + rec + 1e-6) if (prec + rec) > 0 else 0

                ious.append(iou)
                precisions.append(prec)
                recalls.append(rec)
                if name == "val":
                    f1s.append(f1)
                else:
                    f1s.append(np.nan)  # F1 only for validation

            # Aggregate metrics
            mean_loss = np.nanmean(losses)
            mean_acc = np.nanmean(accs)
            mean_iou_val = np.nanmean(mean_ious)

            # Prepare CSV row
            row = [epoch + 1, name, mean_loss, mean_acc, mean_iou_val] + ious + precisions + recalls
            if name == "val":
                row += f1s

            rows.append(row)

            # Print metrics
            metrics_str = (
                f"IoU: {[f'{self.class_names[c]}: {iou:.4f}' for c, iou in enumerate(ious)]}, "
                f"Prec: {[f'{self.class_names[c]}: {prec:.4f}' for c, prec in enumerate(precisions)]}, "
                f"Rec: {[f'{self.class_names[c]}: {rec:.4f}' for c, rec in enumerate(recalls)]}"
            )
            if name == "val":
                metrics_str += f", F1: {[f'{self.class_names[c]}: {f1:.4f}' for c, f1 in enumerate(f1s)]}"
            print(f"âœ… Epoch {epoch+1:03d} | {name.upper()} - Loss: {mean_loss:.4f}, "
                  f"Acc: {mean_acc:.4f}, mIoU: {mean_iou_val:.4f}, {metrics_str}")

        # Write to CSV
        with open(self.csv_path, "a", newline="") as f:
            writer = csv.writer(f)
            for row in rows:
                writer.writerow(row)




def create_confusion_matrix(mask_folder, pred_folder, model, output_csv, ignore_values=[0, 255], preprocess_fn=None):
    """
    Create a confusion matrix by using a trained TensorFlow/Keras model to predict labels for patch
    images in pred_folder, comparing with corresponding ground truth masks in mask_folder. Matches
    files by filename. Ignores specified values (e.g., 0 for background, 255 for ignore). Saves the
    result to a CSV file.
    
    Parameters:
    - mask_folder (str): Path to folder containing .npy patch mask files (ground truth).
    - pred_folder (str): Path to folder containing .npy patch image files for prediction.
    - model: Trained TensorFlow/Keras model for predicting patch labels.
    - output_csv (str): Path to save the confusion matrix CSV file.
    - ignore_values (list): List of label values to ignore (default: [0, 255]).
    - preprocess_fn (callable): Optional function to preprocess patch images (e.g., normalize).
    
    Returns:
    - cm (np.ndarray): Confusion matrix where rows are actual labels and columns are predicted labels.
    """
    # Initialize lists for ground truth and predictions
    ground_truth_list = []
    predictions_list = []

    # Process each .npy mask file
    for file in os.listdir(mask_folder):
        if file.endswith('.npy'):
            mask_path = os.path.join(mask_folder, file)
            
            # Load ground truth patch
            gt_patch = np.load(mask_path)
            if gt_patch.ndim != 2:
                gt_patch = gt_patch.squeeze()
                if gt_patch.ndim != 2:
                    raise ValueError(f"Ground truth patch {file} is not 2D: shape {gt_patch.shape}")
            h, w = gt_patch.shape
            print(f"Loaded mask {file} with shape: ({h}, {w})")

            # Load corresponding patch image
            img_file = os.path.join(pred_folder, file)
            if not os.path.exists(img_file):
                raise ValueError(f"Patch image {img_file} not found for mask {file}")
            img_patch = np.load(img_file)
            if img_patch.ndim == 2:
                img_patch = np.expand_dims(img_patch, axis=-1)  # Add channel dimension if grayscale
            if img_patch.ndim != 3:
                raise ValueError(f"Patch image {file} is not 2D or 3D: shape {img_patch.shape}")
            print(f"Loaded patch image {file} with shape: {img_patch.shape}")

            # Preprocess image if preprocess_fn is provided
            if preprocess_fn is not None:
                img_patch = preprocess_fn(img_patch)
            
            # Prepare image for model prediction (add batch dimension)
            img_patch = np.expand_dims(img_patch, axis=0)  # Shape: (1, h, w, c)

            # Generate prediction using the model
            pred_patch = model.predict(img_patch, verbose=0)
            if pred_patch.shape[-1] > 1:  # Multi-class output (1, h, w, num_classes)
                pred_patch = np.argmax(pred_patch, axis=-1)  # Take argmax over classes
            pred_patch = pred_patch[0]  # Remove batch dimension

            if pred_patch.shape != (h, w):
                raise ValueError(f"Prediction shape {pred_patch.shape} does not match mask shape ({h}, {w})")
            print(f"Generated prediction for {file} with shape: {pred_patch.shape}")

            # Flatten and append
            ground_truth_list.append(gt_patch.flatten())
            predictions_list.append(pred_patch.flatten())

    # Concatenate all patches
    ground_truth = np.concatenate(ground_truth_list)
    predictions = np.concatenate(predictions_list)
    print(f"Concatenated ground truth length: {len(ground_truth)}")
    print(f"Concatenated predictions length: {len(predictions)}")

    # Ensure ground truth and predictions have the same length
    if len(ground_truth) != len(predictions):
        raise ValueError("Ground truth and prediction arrays must have the same length after concatenation.")

    # Filter out ignore values (e.g., 0 and 255)
    valid_mask = ~np.isin(ground_truth, ignore_values) & ~np.isin(predictions, ignore_values)
    ground_truth = ground_truth[valid_mask]
    predictions = predictions[valid_mask]
    print(f"After filtering ignore values, ground truth length: {len(ground_truth)}, predictions length: {len(predictions)}")

    # Check if there are valid labels left after filtering
    if len(ground_truth) == 0 or len(predictions) == 0:
        raise ValueError("No valid labels remain after filtering ignore values.")

    # Compute confusion matrix (rows: actual, columns: predicted)
    cm = confusion_matrix(ground_truth, predictions)

    # Get unique labels for indexing (after filtering)
    labels = np.unique(np.concatenate([ground_truth, predictions]))
    
    # Convert to DataFrame for CSV export
    cm_df = pd.DataFrame(cm, index=labels, columns=labels)
    cm_df.index.name = 'Actual'
    cm_df.columns.name = 'Predicted'
    
    # Save to CSV
    cm_df.to_csv(output_csv)
    
    return cm


# --> DECLARE THE INPUT IMAGE AND MASK IMAGE HERE
#model_path = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/unetpp_model.keras'
model_path = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/unetpp_AlphaEarth_adjust0307_1x5.keras'
PATCH_IMAGE_DIR = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/AlphaEarth_Patch_aug'
PATCH_MASK_DIR = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/AlphaEarth_MaskPatch_aug'
PATCH_IMAGE_VAL_DIR = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/AlphaEarth_Patch_aug_val'
PATCH_MASK_VAL_DIR = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/AlphaEarth_MaskPatch_aug_val'
PATCH_IMAGE_TEST_DIR = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/AlphaEarth_Patch_aug_test'
PATCH_MASK_TEST_DIR = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/AlphaEarth_MaskPatch_aug_test'

# --> SET PARAMETERS OF MODEL HERE
#ATTENTION
# DO NOT CHANGE THE NAME OF THE VARIABLE, SINCE FUNCTIONS USE IT
# Change normalized method of classification function based on the method of normalized when trained data
IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 128, 128, 64  # Image dimensions and bands
NUM_CLASSES = 18  # Number of categories
IGNORE_CLASS = None  # or index to ignore
BATCH_SIZE = 32
EPOCHS = 150
L2_FACTOR = 1e-4
SEED = 42
alphaC = 0.3  # alpha for cross entropy, beta for dice loss alpha 0.3 beta 0.7
betaC = 0.7
minority_classes = [8,12,14,16,17]  # Your minority classes

# --> SET PARAMETERS OF INPUT AND OUTPUT FOLDER PATH FOR IMAGE CLASSIFICATION HERE
input_folder = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/AlphaEarth'
predictedImage_path = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/result_AlphaEarth_unetpp'

# --> SET PARAMETERS OF CONFUSION MATRIX HERE
cm_output = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/ConfusionMatrix.csv'
LOG_FILE = '/mnt/RAID100TB/work_RAID/work_Trung/AgrUNET/Log_AlphaEarth_TrainVal.csv'


#--------END OF PARAMETERS----------

train_imgs, train_masks = get_npy_filepaths(PATCH_IMAGE_DIR, PATCH_MASK_DIR)
test_imgs, test_masks = get_npy_filepaths(PATCH_IMAGE_VAL_DIR, PATCH_MASK_VAL_DIR)

# Create datasets old, not focus on minority class
#train_dataset = create_dataset(train_imgs, train_masks, BATCH_SIZE, shuffle=True)
#val_dataset = create_dataset(test_imgs, test_masks, BATCH_SIZE, shuffle=False)

train_dataset = create_dataset_imbalance(train_imgs, train_masks, BATCH_SIZE, minority_classes=minority_classes, shuffle=True)
val_dataset = create_dataset_imbalance(test_imgs, test_masks, BATCH_SIZE, minority_classes=None, shuffle=False)


# Compute steps per epoch
TRAIN_STEPS = math.ceil(len(train_imgs) / BATCH_SIZE)


# Ajdust dynamic weight
class_counts = track_class_counts(train_dataset, num_classes=NUM_CLASSES)
dynamic_weights_cb = DynamicWeightsCallback(class_counts)

for i, w in enumerate(dynamic_weights_cb.get_weights()):
    print(f"Class {i}: {w:.4f}")

if os.path.exists(model_path):
    print("ðŸ“‚ Loading existing model without compiling...")
    model = tf.keras.models.load_model(
        model_path,
        custom_objects={'PerClassIoU': PerClassIoU},
        compile=False  # do NOT compile yet
    )
    print("âœ… Model loaded, now compiling with custom loss and metrics...")
    loss = CombinedLoss(get_weights=dynamic_weights_cb.get_weights, alpha=tf.Variable(alphaC), beta=tf.Variable(betaC))
    model.compile(
        optimizer='adam',
        loss=loss,
        metrics=[
            'accuracy',
            tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),
            tf.keras.metrics.Precision(),
            tf.keras.metrics.Recall(),
            PerClassIoU(num_classes=NUM_CLASSES)
        ]
    )
else:
    print("ðŸ†• No model found. Creating a new model...")
    model = unetpp_model_tf((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), NUM_CLASSES, L2_FACTOR)
    loss = CombinedLoss(get_weights=dynamic_weights_cb.get_weights, alpha=tf.Variable(alphaC), beta=tf.Variable(betaC))
    model.compile(
        optimizer='adam',
        loss=loss,
        metrics=[
            'accuracy',
            tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),
            tf.keras.metrics.Precision(),
            tf.keras.metrics.Recall(),
            PerClassIoU(num_classes=NUM_CLASSES)
        ]
    )


model.summary()

#----CALL BACK-----

iou_logger = IoU_F1_Logger(train_dataset, val_dataset, NUM_CLASSES, csv_path = LOG_FILE)

# Stop training when validation loss doesn't improve for 10 epochs
early_stop_cb = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True,
    verbose=1
)

# Save the best model based on validation loss
checkpoint_cb = ModelCheckpoint(
    filepath=model_path,
    monitor='val_loss',
    save_best_only=True,
    save_weights_only=False,  # Set to True if you're saving only weights
    verbose=1
)

#Adjust alpha and beta of loss function
adaptive_callback = AdaptiveLossCallback(
    loss=loss,
    validation_data=val_dataset,         # Your tf.data.Dataset for validation
    num_classes=NUM_CLASSES,
    ignore_classes=[255],
    csv_path=predictedImage_path+'.csv',
    patience=3,
    slope_scale=1.5,
    min_weight=0.1,
    max_weight=0.9,
    cooldown=3
)

#Learning rate
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    min_lr=1e-6
)

"""
history = model.fit(train_dataset,
                    validation_data=val_dataset,
                    epochs=EPOCHS,
                    #steps_per_epoch=TRAIN_STEPS,
                    callbacks=[
                           dynamic_weights_cb,  # if you're using dynamic weights
                           early_stop_cb,
                           checkpoint_cb,
                           reduce_lr,
                           adaptive_callback,
                           iou_logger
                           ]
                    )


print("Training model completed.")
model.save(model_path)
print(f"Model saved to {model_path}")

try:
    cm = create_confusion_matrix(
                mask_folder=PATCH_MASK_TEST_DIR,
                pred_folder=PATCH_IMAGE_TEST_DIR,
                model=model,  # Replace with your loaded model
                output_csv=cm_output,
                ignore_values=[0, 255],
               
                preprocess_fn= None # Optional: adjust or set to None
            )
    print("Confusion Matrix (rows: Actual, columns: Predicted):")
    print(cm)
except ValueError as e:
    print(f"Error: {e}")

"""

# Create the output directory if it doesn't exist
os.makedirs(predictedImage_path, exist_ok=True)

# Iterate through all image files in the input folder
for filename in os.listdir(input_folder):
    if filename.lower().endswith(('.tif', '.tiff')):  # You can add other image extensions if needed
        input_path = os.path.join(input_folder, filename)

        print(f'Processing: {filename}')
        try:
            # Classify the image
            classified_map = classify_full_image(input_path, model, IMG_HEIGHT)
            # Save the result
            outname = filename[:-4] + '_predicted.tif'
            out_path = os.path.join(predictedImage_path, outname)
            save_classified_geotiff(classified_map, reference_path=input_path, output_path=out_path)
            print(f'Saved: {out_path}')
        except:
            print(f'error: {out_path}')

